{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krpX2-TmLXND"
      },
      "source": [
        "# Import and Hyperparameters\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pickle\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import librosa\n",
        "import librosa.display\n",
        "import tensorflow as tf\n",
        "\n",
        "from collections import Counter\n",
        "from functools import partial\n",
        "from sklearn.metrics import (accuracy_score, recall_score, f1_score,\n",
        "                             precision_score, classification_report, confusion_matrix)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Keras Imports\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import (Dense, Flatten, Conv1D, GlobalAveragePooling1D,\n",
        "                                     LayerNormalization, Input, MaxPooling1D, Multiply,\n",
        "                                     Reshape, Permute, Add, Activation, UpSampling1D)\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "metadata": {
        "id": "hchX3wmLu94Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_global_determinism(seed=42):\n",
        "    \"\"\"\n",
        "    Sets seeds for all random number generators to ensure reproducible results.\n",
        "    \"\"\"\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    print(f\"Global seed set to: {seed}\")\n",
        "\n",
        "SEED = 42\n",
        "set_global_determinism(SEED)"
      ],
      "metadata": {
        "id": "--FHd25yvB0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assumption: The 'data' folder is in the same directory as this notebook in the Git repo\n",
        "BASE_DIR = './data'\n",
        "\n",
        "TRAIN_DIR = os.path.join(BASE_DIR, 'TRAIN')\n",
        "TEST_DIR = os.path.join(BASE_DIR, 'TEST')\n",
        "VAL_DIR = os.path.join(BASE_DIR, 'VALIDATION')\n",
        "\n",
        "# Where to save the trained model and logs locally\n",
        "OUTPUT_DIR = './output'\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)"
      ],
      "metadata": {
        "id": "ONOhzn1MvNIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLING_RATE = 48000\n",
        "INPUT_SHAPE = (SAMPLING_RATE, 1) # 1 second audio\n",
        "BATCH_SIZE = 32\n",
        "epochs = 20\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_CLASSES = 2"
      ],
      "metadata": {
        "id": "mG5DBEhtveEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    os.path.join(WEIGHTS_DIR, 'best_model.keras'),\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "21xwUoJLvjLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRwM-vT7z7Tm",
        "outputId": "20552ac6-58b3-4783-d567-21667101cac5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 6. Helper Functions\n",
        "# ==========================================\n",
        "def save_training_history(history, filename):\n",
        "    \"\"\"Saves training history (loss/acc) for later plotting.\"\"\"\n",
        "    file_path = os.path.join(OUTPUT_DIR, filename)\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(history.history, f)\n",
        "    print(f\"History saved to {file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6szOiRkRlgE"
      },
      "source": [
        "# Preprocessing & Augmentation Functions\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dmfq_shYDaNk"
      },
      "outputs": [],
      "source": [
        "# ==========================================\n",
        "# 1. Data Augmentation Utilities (Noise Injection)\n",
        "# ==========================================\n",
        "\n",
        "def load_noise_file(file_path):\n",
        "    \"\"\"\n",
        "    Loads and decodes the full background noise file into memory.\n",
        "    This should be called once outside the dataset pipeline.\n",
        "    \"\"\"\n",
        "    # Read and decode the WAV file\n",
        "    audio_binary = tf.io.read_file(file_path)\n",
        "    # Decode wav - assuming mono channel for noise\n",
        "    audio, _ = tf.audio.decode_wav(audio_binary, desired_channels=1, desired_samples=-1)\n",
        "    # Remove the channel dimension (N, 1) -> (N,)\n",
        "    return tf.squeeze(audio, axis=-1)\n",
        "\n",
        "def add_background_noise(clean_audio, label, noise_tensor, target_snr):\n",
        "    \"\"\"\n",
        "    Injects a random segment of background noise into the clean audio based on a target SNR.\n",
        "\n",
        "    Args:\n",
        "        clean_audio: Tensor of shape (samples,)\n",
        "        label: The associated class label\n",
        "        noise_tensor: The full pre-loaded noise tensor\n",
        "        target_snr: Linear Signal-to-Noise Ratio (ratio of powers, not dB)\n",
        "\n",
        "    Returns:\n",
        "        noisy_audio: Audio tensor with added noise, clipped to [-1, 1]\n",
        "        label: Unchanged label\n",
        "    \"\"\"\n",
        "    # Ensure inputs are float32\n",
        "    clean_audio = tf.cast(clean_audio, tf.float32)\n",
        "    noise_tensor = tf.cast(noise_tensor, tf.float32)\n",
        "\n",
        "    sample_length = tf.shape(clean_audio)[0]\n",
        "    noise_length = tf.shape(noise_tensor)[0]\n",
        "\n",
        "    # 1. Select a random noise segment matching the audio length\n",
        "    # Note: Assumes noise file is longer than the audio sample\n",
        "    max_offset = noise_length - sample_length\n",
        "\n",
        "    # Safety check: if noise is shorter, repeat it (optional, but good for stability)\n",
        "    # For now, we assume noise_length > sample_length as per your setup\n",
        "    random_offset = tf.random.uniform(shape=(), minval=0, maxval=max_offset, dtype=tf.int32)\n",
        "    noise_segment = tf.slice(noise_tensor, [random_offset], [sample_length])\n",
        "\n",
        "    # 2. Calculate signal and noise power\n",
        "    signal_power = tf.reduce_mean(tf.square(clean_audio))\n",
        "    noise_power = tf.reduce_mean(tf.square(noise_segment))\n",
        "\n",
        "    # 3. Calculate scaling factor for the noise to achieve target SNR\n",
        "    # Formula: SNR = P_signal / P_noise_scaled\n",
        "    # Therefore: P_noise_scaled = P_signal / SNR\n",
        "    # scale = sqrt(P_noise_scaled / P_noise_original)\n",
        "    epsilon = 1e-10  # Avoid division by zero\n",
        "    target_noise_power = signal_power / (target_snr + epsilon)\n",
        "    scale_factor = tf.sqrt(target_noise_power / (noise_power + epsilon))\n",
        "\n",
        "    # 4. Add weighted noise\n",
        "    noisy_audio = clean_audio + (noise_segment * scale_factor)\n",
        "\n",
        "    # 5. Clip to valid audio range [-1.0, 1.0]\n",
        "    noisy_audio = tf.clip_by_value(noisy_audio, -1.0, 1.0)\n",
        "\n",
        "    return noisy_audio, label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the background noise file into memory once\n",
        "background_noise = load_noise_file(NOISE_FILE_PATH)\n",
        "\n",
        "# Create a partial function with fixed noise and SNR arguments\n",
        "# This prepares the function to be mapped over the dataset\n",
        "add_noise_map_fn = partial(\n",
        "    add_background_noise,\n",
        "    noise_tensor=background_noise,\n",
        "    target_snr=SNR\n",
        ")"
      ],
      "metadata": {
        "id": "3sxsaq_bzubJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading Pipeline\n",
        "---"
      ],
      "metadata": {
        "id": "gGo_AytnyDzo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsS7y8OQuVif"
      },
      "outputs": [],
      "source": [
        "def load_data(root_dir):\n",
        "    \"\"\"\n",
        "    Scans the directory for .wav files and assigns labels based on folder names.\n",
        "    \"\"\"\n",
        "    file_paths = []\n",
        "    labels = []\n",
        "\n",
        "    # Check if directory exists to avoid errors\n",
        "    if not os.path.exists(root_dir):\n",
        "        print(f\"Warning: Directory not found: {root_dir}\")\n",
        "        return [], [], []\n",
        "\n",
        "    # Iterate over classes (folders)\n",
        "    for class_name in sorted(os.listdir(root_dir)): # Added sorted for consistency\n",
        "        class_path = os.path.join(root_dir, class_name)\n",
        "\n",
        "        if os.path.isdir(class_path):\n",
        "            for subdir, dirs, files in os.walk(class_path):\n",
        "                for file in files:\n",
        "                    if file.endswith(\".wav\"):\n",
        "                        file_path = os.path.join(subdir, file)\n",
        "                        file_paths.append(file_path)\n",
        "                        labels.append(class_name)\n",
        "\n",
        "    # Convert labels to categorical indices\n",
        "    unique_labels = sorted(set(labels))\n",
        "    label_to_index = {label: index for index, label in enumerate(unique_labels)}\n",
        "    labels = [label_to_index[label] for label in labels]\n",
        "\n",
        "    return file_paths, labels, unique_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9K1BjTnjM3Fn"
      },
      "outputs": [],
      "source": [
        "def preprocess_audio(file_path):\n",
        "    \"\"\"\n",
        "    Reads a WAV file and decodes it into a normalized tensor.\n",
        "    \"\"\"\n",
        "    audio_binary = tf.io.read_file(file_path)\n",
        "    # Using the global SAMPLING_RATE defined in config\n",
        "    audio, _ = tf.audio.decode_wav(audio_binary, desired_channels=1, desired_samples=SAMPLING_RATE)\n",
        "    audio = tf.squeeze(audio, axis=-1)  # Remove the channel dimension (N, 1) -> (N,)\n",
        "    return audio\n",
        "\n",
        "# Function to load the audio files and their labels\n",
        "def load_audio_and_label(file_path, label):\n",
        "    \"\"\"\n",
        "    Wrapper function to map file paths to audio tensors and labels.\n",
        "    \"\"\"\n",
        "    audio = preprocess_audio(file_path)\n",
        "    return audio, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNjLwTldfq8U"
      },
      "outputs": [],
      "source": [
        "# Load file paths and labels\n",
        "train_paths, train_labels, class_names = load_data(TRAIN_DIR)\n",
        "val_paths, val_labels, _ = load_data(VAL_DIR)\n",
        "\n",
        "# Calculate class weights to address dataset imbalance\n",
        "# Note: Uses 'balanced' mode to automatically adjust weights inversely proportional to class frequencies\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_labels),\n",
        "    y=train_labels\n",
        ")\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "print(f\"Class Weights: {class_weight_dict}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjFyafD8Sf49"
      },
      "outputs": [],
      "source": [
        "# Convert integer labels to One-Hot Encoding\n",
        "y_train = tf.keras.utils.to_categorical(train_labels, num_classes=NUM_CLASSES)\n",
        "y_val = tf.keras.utils.to_categorical(val_labels, num_classes=NUM_CLASSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiIFluxPVTMA"
      },
      "outputs": [],
      "source": [
        "\n",
        "# TOGGLE THIS FLAG to switch between \"Noise Robustness\" and \"Clean\" experiments\n",
        "USE_NOISE_AUGMENTATION = True\n",
        "\n",
        "print(f\"Building Dataset... (Noise Augmentation: {USE_NOISE_AUGMENTATION})\")\n",
        "\n",
        "# 1. Create Base Dataset from paths and labels\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_paths, y_train))\n",
        "\n",
        "# 2. Load and Preprocess Audio\n",
        "train_dataset = train_dataset.map(load_audio_and_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# 3. Apply Noise Augmentation (Conditionally)\n",
        "if USE_NOISE_AUGMENTATION:\n",
        "    print(\"Log: Injecting background noise into training data.\")\n",
        "    # Note: add_noise_map_fn must be defined in previous steps\n",
        "    train_dataset = train_dataset.map(add_noise_map_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# 4. Shuffle, Batch, and Prefetch\n",
        "train_dataset = train_dataset.shuffle(buffer_size=len(train_paths))\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "train_dataset = train_dataset.cache()\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "# ==========================================\n",
        "# Validation Set (Always Clean)\n",
        "# ==========================================\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((val_paths, y_val))\n",
        "validation_dataset = validation_dataset.map(load_audio_and_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "validation_dataset = validation_dataset.batch(BATCH_SIZE)\n",
        "validation_dataset = validation_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"Datasets ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofWFuVsORxaz"
      },
      "source": [
        "# Model Architecture & Trainin\n",
        " ---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd4fxICHyfvk",
        "outputId": "50c545ef-b84b-43a0-bea0-638d9fda1f66"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# Model Definitions\n",
        "# ==========================================\n",
        "\n",
        "def build_efficient_cnn(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Standard Efficient-CNN baseline.\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        Conv1D(16, 3, activation='relu', input_shape=input_shape),\n",
        "        LayerNormalization(),\n",
        "        MaxPooling1D(2),\n",
        "\n",
        "        Conv1D(16, 3, activation='relu'),\n",
        "        MaxPooling1D(2),\n",
        "\n",
        "        GlobalAveragePooling1D(),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ], name=\"Efficient_CNN\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_dilated_cnn(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Dilated-CNN to capture wider receptive fields.\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        Conv1D(16, 3, activation='relu', input_shape=input_shape, padding='same'),\n",
        "        LayerNormalization(),\n",
        "        MaxPooling1D(2),\n",
        "\n",
        "        # Dilation blocks\n",
        "        Conv1D(32, 3, activation='relu', padding='same', dilation_rate=2),\n",
        "        LayerNormalization(),\n",
        "\n",
        "        Conv1D(32, 3, activation='relu', padding='same', dilation_rate=4),\n",
        "        LayerNormalization(),\n",
        "        MaxPooling1D(2),\n",
        "\n",
        "        GlobalAveragePooling1D(),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ], name=\"Dilated_CNN\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_se_cnn(input_shape, num_classes, reduction_ratio=4):\n",
        "    \"\"\"\n",
        "    Proposed SE-CNN (Squeeze-and-Excitation) Architecture.\n",
        "    \"\"\"\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # First Conv Block\n",
        "    x = Conv1D(32, 3, activation='relu', padding='same')(input_tensor)\n",
        "    x = LayerNormalization()(x)\n",
        "    x = MaxPooling1D(2)(x)\n",
        "\n",
        "    # --- SE Block Start ---\n",
        "    input_features = x\n",
        "    num_channels = input_features.shape[-1]\n",
        "\n",
        "    # Squeeze: Global Information Embedding\n",
        "    se_branch = GlobalAveragePooling1D()(input_features)\n",
        "\n",
        "    # Excitation: Adaptive Recalibration\n",
        "    se_branch = Dense(num_channels // reduction_ratio, activation='relu')(se_branch)\n",
        "    se_branch = Dense(num_channels, activation='sigmoid')(se_branch)\n",
        "    se_branch = Reshape((1, num_channels))(se_branch)\n",
        "\n",
        "    # Scale: Re-weighting\n",
        "    x = Multiply()([input_features, se_branch])\n",
        "    # --- SE Block End ---\n",
        "\n",
        "    # Second Conv Block\n",
        "    x = Conv1D(32, 3, activation='relu', padding='same')(x)\n",
        "    x = LayerNormalization()(x)\n",
        "    x = MaxPooling1D(2)(x)\n",
        "\n",
        "    # Classification Head\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    x = Dense(32, activation='relu')(x)\n",
        "    x = Dense(16, activation='relu')(x)\n",
        "    output_tensor = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input_tensor, outputs=output_tensor, name=\"SE_CNN_Ours\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the model architecture here: 'Efficient', 'Dilated', or 'SE'\n",
        "MODEL_TYPE = 'SE'\n",
        "\n",
        "if MODEL_TYPE == 'Efficient':\n",
        "    model = build_efficient_cnn(INPUT_SHAPE, NUM_CLASSES)\n",
        "elif MODEL_TYPE == 'Dilated':\n",
        "    model = build_dilated_cnn(INPUT_SHAPE, NUM_CLASSES)\n",
        "elif MODEL_TYPE == 'SE':\n",
        "    model = build_se_cnn(INPUT_SHAPE, NUM_CLASSES, reduction_ratio=4)\n",
        "else:\n",
        "    raise ValueError(\"Unknown Model Type\")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.Recall(name='recall'), tf.keras.metrics.Precision(name='precision')]\n",
        ")"
      ],
      "metadata": {
        "id": "_Ncxr5YE1vUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKsPx_5trhyp"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    class_weight=class_weight_dict,\n",
        "    callbacks=[early_stopping, model_checkpoint],\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnVCnPqRcw-L"
      },
      "outputs": [],
      "source": [
        "model.save_weights(os.path.join(weights_save_dir, 'for_deployment.weights.h5'))\n",
        "save_training_history(history, os.path.join(history_save_dir, 'for_deployment._history.pkl'))\n",
        "save_training_history(history, 'training_history.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7nibaBwSI2h"
      },
      "source": [
        "# Model Evaluation\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsFYRhj62lW_",
        "outputId": "18e6f601-a923-4e93-8ae2-a68177fcb731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Report saved to /content/model_report.docx\n"
          ]
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"\n",
        "    Plots the Loss and Accuracy curves for training and validation.\n",
        "    \"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Loss Plot\n",
        "    ax1.plot(history.history['loss'], label='Train Loss', color='blue')\n",
        "    ax1.plot(history.history['val_loss'], label='Val Loss', color='red', linestyle='--')\n",
        "    ax1.set_title('Loss Curve')\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Loss')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Accuracy Plot\n",
        "    ax2.plot(history.history['accuracy'], label='Train Acc', color='blue')\n",
        "    ax2.plot(history.history['val_accuracy'], label='Val Acc', color='red', linestyle='--')\n",
        "    ax2.set_title('Accuracy Curve')\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    ax2.set_ylabel('Accuracy')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_and_report(model, dataset, class_names):\n",
        "    \"\"\"\n",
        "    Runs inference, calculates metrics, and displays confusion matrix.\n",
        "    \"\"\"\n",
        "    print(\"Running inference on Test Set...\")\n",
        "\n",
        "    # 1. Get Predictions\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    # Iterate over the dataset (unbatching to get sample-by-sample)\n",
        "    for audio_batch, label_batch in dataset:\n",
        "        preds = model.predict(audio_batch, verbose=0)\n",
        "        y_pred.extend(np.argmax(preds, axis=1))\n",
        "        y_true.extend(np.argmax(label_batch.numpy(), axis=1))\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # 2. Print Classification Report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
        "\n",
        "    # 3. Plot Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# ==========================================\n",
        "# Execute Evaluation\n",
        "# ==========================================\n",
        "plot_training_history(history)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_paths, tf.keras.utils.to_categorical(test_labels, NUM_CLASSES)))\n",
        "test_dataset = test_dataset.map(load_audio_and_label).batch(BATCH_SIZE).cache()\n",
        "\n",
        "evaluate_and_report(model, test_dataset, class_names)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "krpX2-TmLXND",
        "I6szOiRkRlgE",
        "gGo_AytnyDzo",
        "ofWFuVsORxaz",
        "d7nibaBwSI2h"
      ],
      "gpuType": "V5E1",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}